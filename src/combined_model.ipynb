{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras import optimizers\n",
    "from keras.preprocessing.image import img_to_array, load_img\n",
    "\n",
    "np.random.seed(2018)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_numeric_training(standardize=True):\n",
    "    data = pd.read_csv('../train.csv')\n",
    "    ID = data.pop('id')\n",
    "    y = data.pop('species')\n",
    "    y = LabelEncoder().fit(y).transform(y)\n",
    "    X = StandardScaler().fit(data).transform(data) if standardize else data.values\n",
    "    return ID, X, y\n",
    "load_numeric_training();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_numeric_test(standardize=True):\n",
    "    data = pd.read_csv('../test.csv')\n",
    "    ID = data.pop('id')\n",
    "    test = StandardScaler().fit(data).transform(data) if standardize else data.values\n",
    "    return ID, test\n",
    "load_numeric_test();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def resize_img(img, max_dim=96):\n",
    "    max_axis = np.argmax(img.size)\n",
    "    scale = max_dim / img.size[max_axis]\n",
    "    return img.resize((int(img.size[0] * scale), int(img.size[1] * scale)))\n",
    "\n",
    "\n",
    "def load_img_data(ids, max_dim=96, center=True):\n",
    "    X = np.empty((len(ids), max_dim, max_dim, 1))\n",
    "    for i, id in enumerate(ids):\n",
    "        img = load_img('../images/{}.jpg'.format(id), grayscale=True)\n",
    "        img = resize_img(img, max_dim=max_dim)\n",
    "        x = img_to_array(img)\n",
    "        h, w = x.shape[:2]\n",
    "        if center:\n",
    "            h1 = (max_dim - h) >> 1\n",
    "            h2 = h1 + h\n",
    "            w1 = (max_dim - w) >> 1\n",
    "            w2 = w1 + w\n",
    "        else:\n",
    "            h1, h2, w1, w2 = 0, h, 0, w\n",
    "        X[i][h1:h2, w1:w2][:] = x\n",
    "    return np.around(X / 255)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_train_data(split=0.9, random_state=7):\n",
    "    ID, X_num_train, y = load_numeric_training()\n",
    "    X_img_train = load_img_data(ID)\n",
    "    sss = StratifiedShuffleSplit(n_splits=1, train_size=split, test_size=1 - split, random_state=random_state)\n",
    "    train_idx, val_idx = next(sss.split(X_num_train, y))\n",
    "    X_num_tr, X_img_tr, y_tr = X_num_train[train_idx], X_img_train[train_idx], y[train_idx]\n",
    "    X_num_val, X_img_val, y_val = X_num_train[val_idx], X_img_train[val_idx], y[val_idx]\n",
    "    return (X_num_tr, X_img_tr, y_tr), (X_num_val, X_img_val, y_val)\n",
    "\n",
    "\n",
    "def load_test_data():\n",
    "    ID, X_num_test = load_numeric_test()\n",
    "    X_img_test = load_img_data(ID)\n",
    "    return ID, X_num_test, X_img_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "(X_num_tr, X_img_tr, y_tr), (X_num_val, X_img_val, y_val) = load_train_data()\n",
    "ID_test, X_num_test, X_img_test = load_test_data()\n",
    "y_tr, y_val = to_categorical(y_tr), to_categorical((y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator, NumpyArrayIterator, array_to_img\n",
    "\n",
    "\n",
    "class ImageDataGenerator2(ImageDataGenerator):\n",
    "    def __init__(self, rotation_range=20, zoom_range=0.2, horizontal_flip=True,\n",
    "                 vertical_flip=True, fill_mode='nearest', X_num_tr=X_num_tr):\n",
    "        super().__init__(rotation_range=20, zoom_range=0.2, horizontal_flip=True,\n",
    "                         vertical_flip=True, fill_mode='nearest')\n",
    "        self.X_num_tr = X_num_tr\n",
    "\n",
    "    def flow(self, X, y=None, batch_size=32, shuffle=True, seed=None,\n",
    "             save_to_dir=None, save_prefix='', save_format='jpeg'):\n",
    "        return NumpyArrayIterator2(X, y, self,\n",
    "                                   batch_size=batch_size, shuffle=shuffle, seed=seed,\n",
    "                                   save_to_dir=save_to_dir, save_prefix=save_prefix,\n",
    "                                   save_format=save_format, X_num_tr=self.X_num_tr)\n",
    "\n",
    "\n",
    "class NumpyArrayIterator2(NumpyArrayIterator):\n",
    "    def __init__(self, X, y, generator, batch_size, shuffle, seed,\n",
    "                 save_to_dir, save_prefix, save_format, X_num_tr):\n",
    "        super().__init__(X, y, generator, batch_size, shuffle, seed,\n",
    "                         save_to_dir, save_prefix, save_format)\n",
    "        self.X_num_tr = X_num_tr\n",
    "\n",
    "    def next(self):\n",
    "        \"\"\"For python 2.x.\n",
    "        # Returns\n",
    "            The next batch.\n",
    "        \"\"\"\n",
    "        # Keeps under lock only the mechanism which advances\n",
    "        # the indexing of each batch.\n",
    "        with self.lock:\n",
    "            index_array = next(self.index_generator)\n",
    "        # The transformation of images is not under thread lock\n",
    "        # so it can be done in parallel\n",
    "        batch_X, batch_y = self._get_batches_of_transformed_samples(index_array)\n",
    "        return {'image': batch_X, 'numerical': self.X_num_tr[index_array]}, batch_y\n",
    "\n",
    "\n",
    "imgen = ImageDataGenerator2(rotation_range=20, zoom_range=0.2, horizontal_flip=True,\n",
    "                            vertical_flip=True, fill_mode='nearest', X_num_tr=X_num_tr)\n",
    "imgen_train = imgen.flow(X_img_tr, y_tr, batch_size=32, seed=7)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.layers import Dense, Dropout, Activation, Convolution2D, MaxPooling2D, \\\n",
    "    Flatten, Input, concatenate\n",
    "from keras.models import Model\n",
    "\n",
    "\n",
    "def combined_model():\n",
    "    image = Input(shape=(96, 96, 1), name='image')\n",
    "    x = Convolution2D(8, (5, 5), input_shape=(96, 96, 1))(image)\n",
    "    x = (Activation('relu'))(x)\n",
    "    x = (MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))(x)\n",
    "\n",
    "    x = Convolution2D(32, (5, 5))(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = (MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))(x)\n",
    "    x = Flatten()(x)\n",
    "\n",
    "    numerical = Input(shape=(192,), name='numerical')\n",
    "    concatenated = concatenate([x, numerical])\n",
    "\n",
    "    x = Dense(100, activation='relu')(concatenated)\n",
    "    x = Dropout(0.5)(x)\n",
    "\n",
    "    out = Dense(99, activation='softmax')(x)\n",
    "\n",
    "    model = Model(inputs=[image, numerical], outputs=out)\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "\n",
    "def image_model():\n",
    "    image = Input(shape=(96, 96, 1), name='image')\n",
    "    x = Convolution2D(8, (5, 5), input_shape=(96, 96, 1))(image)\n",
    "    x = (Activation('relu'))(x)\n",
    "    x = (MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))(x)\n",
    "\n",
    "    x = Convolution2D(32, (5, 5))(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = (MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))(x)\n",
    "    x = Flatten()(x)\n",
    "\n",
    "    x = Dense(100, activation='relu')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "\n",
    "    out = Dense(99, activation='softmax')(x)\n",
    "\n",
    "    model = Model(inputs=image, outputs=out)\n",
    "    model.compile(optimizer=optimizers.Adam(lr=0.002), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = combined_model()\n",
    "model2 = image_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/99\n",
      "26/27 [===========================>..] - ETA: 0s - loss: 4.4072 - acc: 0.0685Epoch 00001: val_loss improved from inf to 3.87056, saving model to leafnet.h5\n",
      "27/27 [==============================] - 7s 252ms/step - loss: 4.3923 - acc: 0.0694 - val_loss: 3.8706 - val_acc: 0.3333\n",
      "Epoch 2/99\n",
      "26/27 [===========================>..] - ETA: 0s - loss: 3.6380 - acc: 0.1828Epoch 00002: val_loss improved from 3.87056 to 2.77812, saving model to leafnet.h5\n",
      "27/27 [==============================] - 4s 132ms/step - loss: 3.6254 - acc: 0.1865 - val_loss: 2.7781 - val_acc: 0.6061\n",
      "Epoch 3/99\n",
      "26/27 [===========================>..] - ETA: 0s - loss: 2.8871 - acc: 0.3160Epoch 00003: val_loss improved from 2.77812 to 1.81859, saving model to leafnet.h5\n",
      "27/27 [==============================] - 4s 131ms/step - loss: 2.8788 - acc: 0.3171 - val_loss: 1.8186 - val_acc: 0.8384\n",
      "Epoch 4/99\n",
      "26/27 [===========================>..] - ETA: 0s - loss: 2.2781 - acc: 0.4279Epoch 00004: val_loss improved from 1.81859 to 1.22954, saving model to leafnet.h5\n",
      "27/27 [==============================] - 4s 131ms/step - loss: 2.2633 - acc: 0.4318 - val_loss: 1.2295 - val_acc: 0.8687\n",
      "Epoch 5/99\n",
      "26/27 [===========================>..] - ETA: 0s - loss: 1.7342 - acc: 0.5695Epoch 00005: val_loss improved from 1.22954 to 0.84131, saving model to leafnet.h5\n",
      "27/27 [==============================] - 4s 133ms/step - loss: 1.7343 - acc: 0.5693 - val_loss: 0.8413 - val_acc: 0.9293\n",
      "Epoch 6/99\n",
      "26/27 [===========================>..] - ETA: 0s - loss: 1.4198 - acc: 0.6204Epoch 00006: val_loss improved from 0.84131 to 0.62283, saving model to leafnet.h5\n",
      "27/27 [==============================] - 4s 134ms/step - loss: 1.4202 - acc: 0.6182 - val_loss: 0.6228 - val_acc: 0.9798\n",
      "Epoch 7/99\n",
      "26/27 [===========================>..] - ETA: 0s - loss: 1.1093 - acc: 0.7223Epoch 00007: val_loss improved from 0.62283 to 0.45255, saving model to leafnet.h5\n",
      "27/27 [==============================] - 4s 132ms/step - loss: 1.1127 - acc: 0.7222 - val_loss: 0.4526 - val_acc: 0.9798\n",
      "Epoch 8/99\n",
      "26/27 [===========================>..] - ETA: 0s - loss: 0.9839 - acc: 0.7370Epoch 00008: val_loss improved from 0.45255 to 0.33556, saving model to leafnet.h5\n",
      "27/27 [==============================] - 4s 138ms/step - loss: 0.9776 - acc: 0.7386 - val_loss: 0.3356 - val_acc: 0.9899\n",
      "Epoch 9/99\n",
      "26/27 [===========================>..] - ETA: 0s - loss: 0.8402 - acc: 0.7463Epoch 00009: val_loss improved from 0.33556 to 0.25035, saving model to leafnet.h5\n",
      "27/27 [==============================] - 4s 136ms/step - loss: 0.8387 - acc: 0.7477 - val_loss: 0.2503 - val_acc: 0.9798\n",
      "Epoch 10/99\n",
      "26/27 [===========================>..] - ETA: 0s - loss: 0.7723 - acc: 0.8076Epoch 00010: val_loss improved from 0.25035 to 0.22820, saving model to leafnet.h5\n",
      "27/27 [==============================] - 4s 136ms/step - loss: 0.7650 - acc: 0.8089 - val_loss: 0.2282 - val_acc: 0.9899\n",
      "Epoch 11/99\n",
      "26/27 [===========================>..] - ETA: 0s - loss: 0.6519 - acc: 0.8299Epoch 00011: val_loss improved from 0.22820 to 0.18410, saving model to leafnet.h5\n",
      "27/27 [==============================] - 4s 137ms/step - loss: 0.6531 - acc: 0.8292 - val_loss: 0.1841 - val_acc: 0.9899\n",
      "Epoch 12/99\n",
      "26/27 [===========================>..] - ETA: 0s - loss: 0.6139 - acc: 0.8366Epoch 00012: val_loss improved from 0.18410 to 0.15199, saving model to leafnet.h5\n",
      "27/27 [==============================] - 4s 138ms/step - loss: 0.6188 - acc: 0.8346 - val_loss: 0.1520 - val_acc: 0.9899\n",
      "Epoch 13/99\n",
      "26/27 [===========================>..] - ETA: 0s - loss: 0.5184 - acc: 0.8590Epoch 00013: val_loss improved from 0.15199 to 0.11171, saving model to leafnet.h5\n",
      "27/27 [==============================] - 4s 155ms/step - loss: 0.5202 - acc: 0.8585 - val_loss: 0.1117 - val_acc: 0.9899\n",
      "Epoch 14/99\n",
      "26/27 [===========================>..] - ETA: 0s - loss: 0.5121 - acc: 0.8676Epoch 00014: val_loss improved from 0.11171 to 0.10201, saving model to leafnet.h5\n",
      "27/27 [==============================] - 5s 169ms/step - loss: 0.5095 - acc: 0.8667 - val_loss: 0.1020 - val_acc: 0.9899\n",
      "Epoch 15/99\n",
      "26/27 [===========================>..] - ETA: 0s - loss: 0.4284 - acc: 0.8924Epoch 00015: val_loss improved from 0.10201 to 0.09225, saving model to leafnet.h5\n",
      "27/27 [==============================] - 4s 155ms/step - loss: 0.4274 - acc: 0.8894 - val_loss: 0.0923 - val_acc: 0.9899\n",
      "Epoch 16/99\n",
      "26/27 [===========================>..] - ETA: 0s - loss: 0.4642 - acc: 0.8647Epoch 00016: val_loss improved from 0.09225 to 0.08053, saving model to leafnet.h5\n",
      "27/27 [==============================] - 4s 145ms/step - loss: 0.4600 - acc: 0.8663 - val_loss: 0.0805 - val_acc: 0.9899\n",
      "Epoch 17/99\n",
      "26/27 [===========================>..] - ETA: 0s - loss: 0.3996 - acc: 0.8979Epoch 00017: val_loss improved from 0.08053 to 0.07143, saving model to leafnet.h5\n",
      "27/27 [==============================] - 4s 140ms/step - loss: 0.3993 - acc: 0.8971 - val_loss: 0.0714 - val_acc: 1.0000\n",
      "Epoch 18/99\n",
      "26/27 [===========================>..] - ETA: 0s - loss: 0.3901 - acc: 0.8998Epoch 00018: val_loss did not improve\n",
      "27/27 [==============================] - 4s 132ms/step - loss: 0.3940 - acc: 0.8966 - val_loss: 0.0751 - val_acc: 1.0000\n",
      "Epoch 19/99\n",
      "26/27 [===========================>..] - ETA: 0s - loss: 0.3374 - acc: 0.9056Epoch 00019: val_loss improved from 0.07143 to 0.06615, saving model to leafnet.h5\n",
      "27/27 [==============================] - 4s 134ms/step - loss: 0.3330 - acc: 0.9056 - val_loss: 0.0662 - val_acc: 1.0000\n",
      "Epoch 20/99\n",
      "26/27 [===========================>..] - ETA: 0s - loss: 0.3416 - acc: 0.9154Epoch 00020: val_loss improved from 0.06615 to 0.06130, saving model to leafnet.h5\n",
      "27/27 [==============================] - 4s 133ms/step - loss: 0.3448 - acc: 0.9162 - val_loss: 0.0613 - val_acc: 0.9899\n",
      "Epoch 21/99\n",
      "26/27 [===========================>..] - ETA: 0s - loss: 0.2676 - acc: 0.9284Epoch 00021: val_loss improved from 0.06130 to 0.05594, saving model to leafnet.h5\n",
      "27/27 [==============================] - 4s 134ms/step - loss: 0.2632 - acc: 0.9299 - val_loss: 0.0559 - val_acc: 0.9899\n",
      "Epoch 22/99\n",
      "26/27 [===========================>..] - ETA: 0s - loss: 0.2834 - acc: 0.9380Epoch 00022: val_loss improved from 0.05594 to 0.04210, saving model to leafnet.h5\n",
      "27/27 [==============================] - 4s 132ms/step - loss: 0.2857 - acc: 0.9380 - val_loss: 0.0421 - val_acc: 1.0000\n",
      "Epoch 23/99\n",
      "26/27 [===========================>..] - ETA: 0s - loss: 0.2685 - acc: 0.9284Epoch 00023: val_loss did not improve\n",
      "27/27 [==============================] - 4s 130ms/step - loss: 0.2714 - acc: 0.9264 - val_loss: 0.0449 - val_acc: 1.0000\n",
      "Epoch 24/99\n",
      "26/27 [===========================>..] - ETA: 0s - loss: 0.2149 - acc: 0.9519Epoch 00024: val_loss did not improve\n",
      "27/27 [==============================] - 3s 129ms/step - loss: 0.2171 - acc: 0.9502 - val_loss: 0.0461 - val_acc: 1.0000\n",
      "Epoch 25/99\n",
      "26/27 [===========================>..] - ETA: 0s - loss: 0.2642 - acc: 0.9301Epoch 00025: val_loss did not improve\n",
      "27/27 [==============================] - 4s 131ms/step - loss: 0.2617 - acc: 0.9303 - val_loss: 0.0442 - val_acc: 1.0000\n",
      "Epoch 26/99\n",
      "26/27 [===========================>..] - ETA: 0s - loss: 0.2227 - acc: 0.9495Epoch 00026: val_loss improved from 0.04210 to 0.03581, saving model to leafnet.h5\n",
      "27/27 [==============================] - 4s 131ms/step - loss: 0.2210 - acc: 0.9514 - val_loss: 0.0358 - val_acc: 1.0000\n",
      "Epoch 27/99\n",
      "26/27 [===========================>..] - ETA: 0s - loss: 0.2097 - acc: 0.9481Epoch 00027: val_loss improved from 0.03581 to 0.03367, saving model to leafnet.h5\n",
      "27/27 [==============================] - 4s 132ms/step - loss: 0.2063 - acc: 0.9500 - val_loss: 0.0337 - val_acc: 1.0000\n",
      "Epoch 28/99\n",
      "26/27 [===========================>..] - ETA: 0s - loss: 0.2022 - acc: 0.9435Epoch 00028: val_loss improved from 0.03367 to 0.02956, saving model to leafnet.h5\n",
      "27/27 [==============================] - 4s 133ms/step - loss: 0.2046 - acc: 0.9429 - val_loss: 0.0296 - val_acc: 1.0000\n",
      "Epoch 29/99\n",
      "26/27 [===========================>..] - ETA: 0s - loss: 0.1858 - acc: 0.9495Epoch 00029: val_loss improved from 0.02956 to 0.02671, saving model to leafnet.h5\n",
      "27/27 [==============================] - 4s 132ms/step - loss: 0.1837 - acc: 0.9502 - val_loss: 0.0267 - val_acc: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/99\n",
      "26/27 [===========================>..] - ETA: 0s - loss: 0.1971 - acc: 0.9541Epoch 00030: val_loss did not improve\n",
      "27/27 [==============================] - 3s 130ms/step - loss: 0.2008 - acc: 0.9512 - val_loss: 0.0304 - val_acc: 1.0000\n",
      "Epoch 31/99\n",
      "26/27 [===========================>..] - ETA: 0s - loss: 0.1487 - acc: 0.9695Epoch 00031: val_loss did not improve\n",
      "27/27 [==============================] - 3s 129ms/step - loss: 0.1477 - acc: 0.9706 - val_loss: 0.0325 - val_acc: 1.0000\n",
      "Epoch 32/99\n",
      "26/27 [===========================>..] - ETA: 0s - loss: 0.1529 - acc: 0.9657Epoch 00032: val_loss improved from 0.02671 to 0.02656, saving model to leafnet.h5\n",
      "27/27 [==============================] - 4s 131ms/step - loss: 0.1555 - acc: 0.9647 - val_loss: 0.0266 - val_acc: 1.0000\n",
      "Epoch 33/99\n",
      "26/27 [===========================>..] - ETA: 0s - loss: 0.1754 - acc: 0.9513Epoch 00033: val_loss did not improve\n",
      "27/27 [==============================] - 3s 129ms/step - loss: 0.1720 - acc: 0.9531 - val_loss: 0.0267 - val_acc: 1.0000\n",
      "Epoch 34/99\n",
      "26/27 [===========================>..] - ETA: 0s - loss: 0.1586 - acc: 0.9651Epoch 00034: val_loss improved from 0.02656 to 0.02546, saving model to leafnet.h5\n",
      "27/27 [==============================] - 4s 130ms/step - loss: 0.1602 - acc: 0.9641 - val_loss: 0.0255 - val_acc: 1.0000\n",
      "Epoch 35/99\n",
      "26/27 [===========================>..] - ETA: 0s - loss: 0.1686 - acc: 0.9651Epoch 00035: val_loss did not improve\n",
      "27/27 [==============================] - 3s 129ms/step - loss: 0.1687 - acc: 0.9653 - val_loss: 0.0293 - val_acc: 0.9899\n",
      "Epoch 36/99\n",
      "26/27 [===========================>..] - ETA: 0s - loss: 0.1510 - acc: 0.9615Epoch 00036: val_loss did not improve\n",
      "27/27 [==============================] - 3s 128ms/step - loss: 0.1475 - acc: 0.9630 - val_loss: 0.0278 - val_acc: 0.9899\n",
      "Epoch 37/99\n",
      "26/27 [===========================>..] - ETA: 0s - loss: 0.1451 - acc: 0.9663Epoch 00037: val_loss did not improve\n",
      "27/27 [==============================] - 3s 129ms/step - loss: 0.1452 - acc: 0.9653 - val_loss: 0.0319 - val_acc: 0.9899\n",
      "Epoch 38/99\n",
      "26/27 [===========================>..] - ETA: 0s - loss: 0.1508 - acc: 0.9553Epoch 00038: val_loss improved from 0.02546 to 0.02422, saving model to leafnet.h5\n",
      "27/27 [==============================] - 4s 132ms/step - loss: 0.1529 - acc: 0.9535 - val_loss: 0.0242 - val_acc: 1.0000\n",
      "Epoch 39/99\n",
      "26/27 [===========================>..] - ETA: 0s - loss: 0.1288 - acc: 0.9635Epoch 00039: val_loss improved from 0.02422 to 0.01953, saving model to leafnet.h5\n",
      "27/27 [==============================] - 4s 131ms/step - loss: 0.1279 - acc: 0.9649 - val_loss: 0.0195 - val_acc: 1.0000\n",
      "Epoch 40/99\n",
      "26/27 [===========================>..] - ETA: 0s - loss: 0.1152 - acc: 0.9772Epoch 00040: val_loss improved from 0.01953 to 0.01843, saving model to leafnet.h5\n",
      "27/27 [==============================] - 4s 131ms/step - loss: 0.1153 - acc: 0.9780 - val_loss: 0.0184 - val_acc: 1.0000\n",
      "Epoch 41/99\n",
      "26/27 [===========================>..] - ETA: 0s - loss: 0.1170 - acc: 0.9709Epoch 00041: val_loss did not improve\n",
      "27/27 [==============================] - 3s 129ms/step - loss: 0.1205 - acc: 0.9709 - val_loss: 0.0220 - val_acc: 1.0000\n",
      "Epoch 42/99\n",
      "26/27 [===========================>..] - ETA: 0s - loss: 0.1148 - acc: 0.9733Epoch 00042: val_loss did not improve\n",
      "27/27 [==============================] - 3s 129ms/step - loss: 0.1139 - acc: 0.9743 - val_loss: 0.0216 - val_acc: 1.0000\n",
      "Epoch 43/99\n",
      "26/27 [===========================>..] - ETA: 0s - loss: 0.1143 - acc: 0.9700Epoch 00043: val_loss improved from 0.01843 to 0.01386, saving model to leafnet.h5\n",
      "27/27 [==============================] - 4s 131ms/step - loss: 0.1132 - acc: 0.9711 - val_loss: 0.0139 - val_acc: 1.0000\n",
      "Epoch 44/99\n",
      "26/27 [===========================>..] - ETA: 0s - loss: 0.1116 - acc: 0.9808Epoch 00044: val_loss did not improve\n",
      "27/27 [==============================] - 3s 129ms/step - loss: 0.1094 - acc: 0.9815 - val_loss: 0.0153 - val_acc: 1.0000\n",
      "Epoch 45/99\n",
      "26/27 [===========================>..] - ETA: 0s - loss: 0.1180 - acc: 0.9675Epoch 00045: val_loss did not improve\n",
      "27/27 [==============================] - 3s 129ms/step - loss: 0.1182 - acc: 0.9676 - val_loss: 0.0183 - val_acc: 1.0000\n",
      "Epoch 46/99\n",
      "26/27 [===========================>..] - ETA: 0s - loss: 0.1198 - acc: 0.9683Epoch 00046: val_loss did not improve\n",
      "27/27 [==============================] - 3s 129ms/step - loss: 0.1211 - acc: 0.9672 - val_loss: 0.0236 - val_acc: 1.0000\n",
      "Epoch 47/99\n",
      "26/27 [===========================>..] - ETA: 0s - loss: 0.1104 - acc: 0.9748Epoch 00047: val_loss did not improve\n",
      "27/27 [==============================] - 3s 129ms/step - loss: 0.1113 - acc: 0.9745 - val_loss: 0.0223 - val_acc: 0.9899\n",
      "Epoch 48/99\n",
      "26/27 [===========================>..] - ETA: 0s - loss: 0.1019 - acc: 0.9796Epoch 00048: val_loss did not improve\n",
      "27/27 [==============================] - 4s 130ms/step - loss: 0.1016 - acc: 0.9803 - val_loss: 0.0187 - val_acc: 0.9899\n",
      "Epoch 49/99\n",
      "26/27 [===========================>..] - ETA: 0s - loss: 0.0847 - acc: 0.9781Epoch 00049: val_loss did not improve\n",
      "27/27 [==============================] - 4s 132ms/step - loss: 0.0842 - acc: 0.9790 - val_loss: 0.0196 - val_acc: 1.0000\n",
      "Epoch 50/99\n",
      "26/27 [===========================>..] - ETA: 0s - loss: 0.1012 - acc: 0.9784Epoch 00050: val_loss did not improve\n",
      "27/27 [==============================] - 4s 131ms/step - loss: 0.1010 - acc: 0.9780 - val_loss: 0.0171 - val_acc: 1.0000\n",
      "Epoch 51/99\n",
      "26/27 [===========================>..] - ETA: 0s - loss: 0.0977 - acc: 0.9724Epoch 00051: val_loss improved from 0.01386 to 0.01167, saving model to leafnet.h5\n",
      "27/27 [==============================] - 4s 132ms/step - loss: 0.0966 - acc: 0.9722 - val_loss: 0.0117 - val_acc: 1.0000\n",
      "Epoch 52/99\n",
      "26/27 [===========================>..] - ETA: 0s - loss: 0.0965 - acc: 0.9748Epoch 00052: val_loss did not improve\n",
      "27/27 [==============================] - 3s 129ms/step - loss: 0.0948 - acc: 0.9745 - val_loss: 0.0178 - val_acc: 0.9899\n",
      "Epoch 53/99\n",
      "26/27 [===========================>..] - ETA: 0s - loss: 0.0746 - acc: 0.9830Epoch 00053: val_loss did not improve\n",
      "27/27 [==============================] - 4s 130ms/step - loss: 0.0747 - acc: 0.9824 - val_loss: 0.0144 - val_acc: 1.0000\n",
      "Epoch 54/99\n",
      "26/27 [===========================>..] - ETA: 0s - loss: 0.0911 - acc: 0.9805Epoch 00054: val_loss did not improve\n",
      "27/27 [==============================] - 3s 129ms/step - loss: 0.0900 - acc: 0.9801 - val_loss: 0.0154 - val_acc: 1.0000\n",
      "Epoch 55/99\n",
      "26/27 [===========================>..] - ETA: 0s - loss: 0.1095 - acc: 0.9760Epoch 00055: val_loss did not improve\n",
      "27/27 [==============================] - 4s 130ms/step - loss: 0.1063 - acc: 0.9768 - val_loss: 0.0195 - val_acc: 1.0000\n",
      "Epoch 56/99\n",
      "26/27 [===========================>..] - ETA: 0s - loss: 0.0907 - acc: 0.9772Epoch 00056: val_loss did not improve\n",
      "27/27 [==============================] - 3s 130ms/step - loss: 0.0884 - acc: 0.9780 - val_loss: 0.0148 - val_acc: 1.0000\n",
      "Epoch 57/99\n",
      "26/27 [===========================>..] - ETA: 0s - loss: 0.0860 - acc: 0.9796Epoch 00057: val_loss did not improve\n",
      "27/27 [==============================] - 4s 137ms/step - loss: 0.0856 - acc: 0.9792 - val_loss: 0.0155 - val_acc: 0.9899\n",
      "Epoch 58/99\n",
      "26/27 [===========================>..] - ETA: 0s - loss: 0.0800 - acc: 0.9743Epoch 00058: val_loss did not improve\n",
      "27/27 [==============================] - 3s 129ms/step - loss: 0.0816 - acc: 0.9753 - val_loss: 0.0126 - val_acc: 1.0000\n",
      "Epoch 59/99\n",
      "26/27 [===========================>..] - ETA: 0s - loss: 0.0805 - acc: 0.9796Epoch 00059: val_loss did not improve\n",
      "27/27 [==============================] - 4s 137ms/step - loss: 0.0789 - acc: 0.9803 - val_loss: 0.0145 - val_acc: 1.0000\n",
      "Epoch 60/99\n",
      "26/27 [===========================>..] - ETA: 0s - loss: 0.0800 - acc: 0.9820Epoch 00060: val_loss did not improve\n",
      "27/27 [==============================] - 4s 166ms/step - loss: 0.0795 - acc: 0.9826 - val_loss: 0.0162 - val_acc: 0.9899\n",
      "Epoch 61/99\n",
      "26/27 [===========================>..] - ETA: 0s - loss: 0.0718 - acc: 0.9832Epoch 00061: val_loss did not improve\n",
      "27/27 [==============================] - 4s 159ms/step - loss: 0.0701 - acc: 0.9838 - val_loss: 0.0126 - val_acc: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 62/99\n",
      "26/27 [===========================>..] - ETA: 0s - loss: 0.0812 - acc: 0.9796Epoch 00062: val_loss did not improve\n",
      "27/27 [==============================] - 4s 159ms/step - loss: 0.0805 - acc: 0.9792 - val_loss: 0.0141 - val_acc: 1.0000\n",
      "Epoch 63/99\n",
      "26/27 [===========================>..] - ETA: 0s - loss: 0.0962 - acc: 0.9736Epoch 00063: val_loss did not improve\n",
      "27/27 [==============================] - 4s 160ms/step - loss: 0.0965 - acc: 0.9734 - val_loss: 0.0188 - val_acc: 1.0000\n",
      "Epoch 64/99\n",
      "26/27 [===========================>..] - ETA: 0s - loss: 0.0845 - acc: 0.9757Epoch 00064: val_loss did not improve\n",
      "27/27 [==============================] - 4s 164ms/step - loss: 0.0843 - acc: 0.9755 - val_loss: 0.0180 - val_acc: 0.9899\n",
      "Epoch 65/99\n",
      "26/27 [===========================>..] - ETA: 0s - loss: 0.0687 - acc: 0.9842Epoch 00065: val_loss improved from 0.01167 to 0.01166, saving model to leafnet.h5\n",
      "27/27 [==============================] - 4s 153ms/step - loss: 0.0679 - acc: 0.9847 - val_loss: 0.0117 - val_acc: 1.0000\n",
      "Epoch 66/99\n",
      "26/27 [===========================>..] - ETA: 0s - loss: 0.0739 - acc: 0.9808Epoch 00066: val_loss did not improve\n",
      "27/27 [==============================] - 4s 151ms/step - loss: 0.0763 - acc: 0.9803 - val_loss: 0.0124 - val_acc: 1.0000\n",
      "Epoch 67/99\n",
      "26/27 [===========================>..] - ETA: 0s - loss: 0.0746 - acc: 0.9748Epoch 00067: val_loss did not improve\n",
      "27/27 [==============================] - 4s 150ms/step - loss: 0.0741 - acc: 0.9757 - val_loss: 0.0164 - val_acc: 1.0000\n",
      "Epoch 68/99\n",
      "26/27 [===========================>..] - ETA: 0s - loss: 0.0609 - acc: 0.9842Epoch 00068: val_loss did not improve\n",
      "27/27 [==============================] - 4s 139ms/step - loss: 0.0602 - acc: 0.9847 - val_loss: 0.0119 - val_acc: 1.0000\n",
      "Epoch 69/99\n",
      "26/27 [===========================>..] - ETA: 0s - loss: 0.0769 - acc: 0.9765Epoch 00069: val_loss did not improve\n",
      "27/27 [==============================] - 4s 139ms/step - loss: 0.0761 - acc: 0.9774 - val_loss: 0.0132 - val_acc: 1.0000\n",
      "Epoch 70/99\n",
      "26/27 [===========================>..] - ETA: 0s - loss: 0.0533 - acc: 0.9868Epoch 00070: val_loss did not improve\n",
      "27/27 [==============================] - 4s 138ms/step - loss: 0.0518 - acc: 0.9873 - val_loss: 0.0132 - val_acc: 0.9899\n",
      "Epoch 71/99\n",
      "26/27 [===========================>..] - ETA: 0s - loss: 0.0531 - acc: 0.9854Epoch 00071: val_loss improved from 0.01166 to 0.00902, saving model to leafnet.h5\n",
      "27/27 [==============================] - 4s 136ms/step - loss: 0.0528 - acc: 0.9859 - val_loss: 0.0090 - val_acc: 1.0000\n",
      "Epoch 72/99\n",
      "26/27 [===========================>..] - ETA: 0s - loss: 0.0751 - acc: 0.9832Epoch 00072: val_loss did not improve\n",
      "27/27 [==============================] - 4s 134ms/step - loss: 0.0745 - acc: 0.9838 - val_loss: 0.0134 - val_acc: 1.0000\n",
      "Epoch 73/99\n",
      "26/27 [===========================>..] - ETA: 0s - loss: 0.0526 - acc: 0.9880Epoch 00073: val_loss did not improve\n",
      "27/27 [==============================] - 4s 135ms/step - loss: 0.0524 - acc: 0.9884 - val_loss: 0.0099 - val_acc: 1.0000\n",
      "Epoch 74/99\n",
      "26/27 [===========================>..] - ETA: 0s - loss: 0.0505 - acc: 0.9868Epoch 00074: val_loss improved from 0.00902 to 0.00820, saving model to leafnet.h5\n",
      "27/27 [==============================] - 4s 136ms/step - loss: 0.0503 - acc: 0.9873 - val_loss: 0.0082 - val_acc: 1.0000\n",
      "Epoch 75/99\n",
      "26/27 [===========================>..] - ETA: 0s - loss: 0.0637 - acc: 0.9844Epoch 00075: val_loss did not improve\n",
      "27/27 [==============================] - 4s 134ms/step - loss: 0.0629 - acc: 0.9850 - val_loss: 0.0114 - val_acc: 1.0000\n",
      "Epoch 76/99\n",
      "26/27 [===========================>..] - ETA: 0s - loss: 0.0505 - acc: 0.9868Epoch 00076: val_loss did not improve\n",
      "27/27 [==============================] - 4s 134ms/step - loss: 0.0499 - acc: 0.9873 - val_loss: 0.0110 - val_acc: 1.0000\n",
      "Epoch 77/99\n",
      "26/27 [===========================>..] - ETA: 0s - loss: 0.0644 - acc: 0.9880Epoch 00077: val_loss did not improve\n",
      "27/27 [==============================] - 4s 134ms/step - loss: 0.0635 - acc: 0.9884 - val_loss: 0.0112 - val_acc: 0.9899\n",
      "Epoch 78/99\n",
      "26/27 [===========================>..] - ETA: 0s - loss: 0.0485 - acc: 0.9904Epoch 00078: val_loss did not improve\n",
      "27/27 [==============================] - 4s 135ms/step - loss: 0.0471 - acc: 0.9907 - val_loss: 0.0100 - val_acc: 1.0000\n",
      "Epoch 79/99\n",
      "26/27 [===========================>..] - ETA: 0s - loss: 0.0519 - acc: 0.9902Epoch 00079: val_loss did not improve\n",
      "27/27 [==============================] - 4s 135ms/step - loss: 0.0523 - acc: 0.9894 - val_loss: 0.0094 - val_acc: 1.0000\n",
      "Epoch 80/99\n",
      "26/27 [===========================>..] - ETA: 0s - loss: 0.0571 - acc: 0.9856Epoch 00080: val_loss did not improve\n",
      "27/27 [==============================] - 4s 134ms/step - loss: 0.0555 - acc: 0.9861 - val_loss: 0.0137 - val_acc: 0.9899\n",
      "Epoch 81/99\n",
      "26/27 [===========================>..] - ETA: 0s - loss: 0.0480 - acc: 0.9880Epoch 00081: val_loss did not improve\n",
      "27/27 [==============================] - 4s 135ms/step - loss: 0.0471 - acc: 0.9884 - val_loss: 0.0110 - val_acc: 1.0000\n",
      "Epoch 82/99\n",
      "26/27 [===========================>..] - ETA: 0s - loss: 0.0470 - acc: 0.9890Epoch 00082: val_loss did not improve\n",
      "27/27 [==============================] - 4s 134ms/step - loss: 0.0468 - acc: 0.9894 - val_loss: 0.0135 - val_acc: 0.9899\n",
      "Epoch 83/99\n",
      "26/27 [===========================>..] - ETA: 0s - loss: 0.0560 - acc: 0.9839Epoch 00083: val_loss improved from 0.00820 to 0.00738, saving model to leafnet.h5\n",
      "27/27 [==============================] - 4s 136ms/step - loss: 0.0573 - acc: 0.9834 - val_loss: 0.0074 - val_acc: 1.0000\n",
      "Epoch 84/99\n",
      "26/27 [===========================>..] - ETA: 0s - loss: 0.0505 - acc: 0.9880Epoch 00084: val_loss did not improve\n",
      "27/27 [==============================] - 4s 133ms/step - loss: 0.0504 - acc: 0.9871 - val_loss: 0.0081 - val_acc: 1.0000\n",
      "Epoch 85/99\n",
      "26/27 [===========================>..] - ETA: 0s - loss: 0.0301 - acc: 0.9964Epoch 00085: val_loss did not improve\n",
      "27/27 [==============================] - 4s 135ms/step - loss: 0.0297 - acc: 0.9965 - val_loss: 0.0077 - val_acc: 1.0000\n",
      "Epoch 86/99\n",
      "26/27 [===========================>..] - ETA: 0s - loss: 0.0509 - acc: 0.9808Epoch 00086: val_loss did not improve\n",
      "27/27 [==============================] - 4s 134ms/step - loss: 0.0496 - acc: 0.9815 - val_loss: 0.0076 - val_acc: 1.0000\n",
      "Epoch 87/99\n",
      "26/27 [===========================>..] - ETA: 0s - loss: 0.0524 - acc: 0.9868Epoch 00087: val_loss did not improve\n",
      "27/27 [==============================] - 4s 133ms/step - loss: 0.0508 - acc: 0.9873 - val_loss: 0.0103 - val_acc: 1.0000\n",
      "Epoch 88/99\n",
      "26/27 [===========================>..] - ETA: 0s - loss: 0.0649 - acc: 0.9832Epoch 00088: val_loss improved from 0.00738 to 0.00712, saving model to leafnet.h5\n",
      "27/27 [==============================] - 4s 136ms/step - loss: 0.0642 - acc: 0.9838 - val_loss: 0.0071 - val_acc: 1.0000\n",
      "Epoch 89/99\n",
      "26/27 [===========================>..] - ETA: 0s - loss: 0.0414 - acc: 0.9890Epoch 00089: val_loss did not improve\n",
      "27/27 [==============================] - 4s 135ms/step - loss: 0.0405 - acc: 0.9894 - val_loss: 0.0086 - val_acc: 1.0000\n",
      "Epoch 90/99\n",
      "26/27 [===========================>..] - ETA: 0s - loss: 0.0409 - acc: 0.9902Epoch 00090: val_loss did not improve\n",
      "27/27 [==============================] - 4s 134ms/step - loss: 0.0398 - acc: 0.9905 - val_loss: 0.0096 - val_acc: 1.0000\n",
      "Epoch 91/99\n",
      "26/27 [===========================>..] - ETA: 0s - loss: 0.0467 - acc: 0.9892Epoch 00091: val_loss improved from 0.00712 to 0.00590, saving model to leafnet.h5\n",
      "27/27 [==============================] - 4s 136ms/step - loss: 0.0464 - acc: 0.9884 - val_loss: 0.0059 - val_acc: 1.0000\n",
      "Epoch 92/99\n",
      "26/27 [===========================>..] - ETA: 0s - loss: 0.0277 - acc: 0.9952Epoch 00092: val_loss improved from 0.00590 to 0.00573, saving model to leafnet.h5\n",
      "27/27 [==============================] - 4s 137ms/step - loss: 0.0294 - acc: 0.9942 - val_loss: 0.0057 - val_acc: 1.0000\n",
      "Epoch 93/99\n",
      "26/27 [===========================>..] - ETA: 0s - loss: 0.0332 - acc: 0.9928Epoch 00093: val_loss did not improve\n",
      "27/27 [==============================] - 4s 135ms/step - loss: 0.0333 - acc: 0.9931 - val_loss: 0.0063 - val_acc: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 94/99\n",
      "26/27 [===========================>..] - ETA: 0s - loss: 0.0508 - acc: 0.9880Epoch 00094: val_loss did not improve\n",
      "27/27 [==============================] - 4s 134ms/step - loss: 0.0502 - acc: 0.9884 - val_loss: 0.0067 - val_acc: 1.0000\n",
      "Epoch 95/99\n",
      "26/27 [===========================>..] - ETA: 0s - loss: 0.0494 - acc: 0.9904Epoch 00095: val_loss did not improve\n",
      "27/27 [==============================] - 4s 133ms/step - loss: 0.0545 - acc: 0.9884 - val_loss: 0.0075 - val_acc: 1.0000\n",
      "Epoch 96/99\n",
      "26/27 [===========================>..] - ETA: 0s - loss: 0.0321 - acc: 0.9962Epoch 00096: val_loss did not improve\n",
      "27/27 [==============================] - 4s 134ms/step - loss: 0.0317 - acc: 0.9963 - val_loss: 0.0072 - val_acc: 1.0000\n",
      "Epoch 97/99\n",
      "26/27 [===========================>..] - ETA: 0s - loss: 0.0323 - acc: 0.9940Epoch 00097: val_loss did not improve\n",
      "27/27 [==============================] - 4s 135ms/step - loss: 0.0314 - acc: 0.9942 - val_loss: 0.0076 - val_acc: 1.0000\n",
      "Epoch 98/99\n",
      "26/27 [===========================>..] - ETA: 0s - loss: 0.0293 - acc: 0.9940Epoch 00098: val_loss did not improve\n",
      "27/27 [==============================] - 4s 134ms/step - loss: 0.0310 - acc: 0.9931 - val_loss: 0.0062 - val_acc: 1.0000\n",
      "Epoch 99/99\n",
      "26/27 [===========================>..] - ETA: 0s - loss: 0.0353 - acc: 0.9868Epoch 00099: val_loss improved from 0.00573 to 0.00492, saving model to leafnet.h5\n",
      "27/27 [==============================] - 4s 137ms/step - loss: 0.0343 - acc: 0.9873 - val_loss: 0.0049 - val_acc: 1.0000\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.models import load_model\n",
    "\n",
    "def combined_generator(imgen):\n",
    "    while True:\n",
    "        for i in range(891 // 32):\n",
    "            batch_x, batch_y = next(imgen)\n",
    "            while len(imgen.index_array)==0:\n",
    "                batch_x, batch_y = next(imgen)\n",
    "            yield batch_x, batch_y\n",
    "\n",
    "\n",
    "best_model_file = 'leafnet.h5'\n",
    "best_model = ModelCheckpoint(best_model_file, monitor='val_loss', verbose=1,\n",
    "                             save_best_only=True)\n",
    "\n",
    "history = model.fit_generator(combined_generator(imgen_train),\n",
    "                              steps_per_epoch=len(X_img_tr) // 32,\n",
    "                              epochs=99, validation_data=[{'image': X_img_val, 'numerical': X_num_val}, y_val]\n",
    "                              , verbose=1, callbacks=[best_model])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
